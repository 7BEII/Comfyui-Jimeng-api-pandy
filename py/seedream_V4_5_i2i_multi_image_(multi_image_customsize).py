import os
import torch
import numpy as np
from PIL import Image
import base64
from io import BytesIO
import json
import requests
import urllib3
import math

# ç¦ç”¨ SSL å®‰å…¨è­¦å‘Š
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

class Seeddream_45_MultiInput_Auto:
    def __init__(self):
        pass

    @classmethod
    def INPUT_TYPES(cls):
        return {
            "required": {
                "api_key": ("STRING", {
                    "default": "", 
                    "multiline": False,
                    "placeholder": "sk-xxx (å¿…å¡«)"
                }),
                "endpoint_id": ("STRING", {
                    "default": "ep-20251204151256-bmd5x", 
                    "multiline": False,
                    "placeholder": "å¿…é¡»æ˜¯ ep- å¼€å¤´çš„ ID"
                }),
                "prompt": ("STRING", {
                    "default": "å°†å›¾1çš„æœè£…æ¢ä¸ºå›¾2çš„æœè£…", 
                    "multiline": True
                }),
                # --- ä¿®æ”¹ï¼šä½¿ç”¨ size ä¸‹æ‹‰èœå• (å« Auto) ---
                "size": (["Auto", "3:4", "1:1", "4:3", "2:3", "3:2", "16:9", "9:16"], {
                    "default": "Auto"
                }),
                # -------------------------------------------------------
                "watermark": ("BOOLEAN", {"default": False}),
            },
            # --- å¤šå›¾å¯é€‰è¾“å…¥ ---
            "optional": {
                "image1": ("IMAGE", {"tooltip": "å‚è€ƒå›¾ 1"}),
                "image2": ("IMAGE", {"tooltip": "å‚è€ƒå›¾ 2"}),
                "image3": ("IMAGE", {"tooltip": "å‚è€ƒå›¾ 3"}),
                "image4": ("IMAGE", {"tooltip": "å‚è€ƒå›¾ 4"}),
            }
        }

    RETURN_TYPES = ("IMAGE",)
    RETURN_NAMES = ("images",)
    FUNCTION = "generate_image"
    CATEGORY = "âœ¨å³æ¢¦AIç”Ÿæˆ"
    
    # è¾…åŠ©ï¼šå¤„ç†å•å¼  Tensor è½¬ Base64
    def _single_tensor_to_base64(self, image_tensor):
        # å³ä½¿æ˜¯å•å¼ è¾“å…¥ï¼ŒComfyUI ä¹Ÿæ˜¯ [1, H, W, C]
        if len(image_tensor.shape) == 4:
            image_tensor = image_tensor[0]
            
        img_np = image_tensor.cpu().numpy()
        img_np = (np.clip(img_np, 0, 1) * 255).astype(np.uint8)
        pil_img = Image.fromarray(img_np)
        
        buff = BytesIO()
        pil_img.save(buff, format="PNG")
        img_b64 = base64.b64encode(buff.getvalue()).decode("utf-8")
        
        # æ·»åŠ å¤´éƒ¨
        return f"data:image/png;base64,{img_b64}"

    def generate_image(self, api_key, endpoint_id, prompt, size, watermark, 
                       image1=None, image2=None, image3=None, image4=None):
        
        # 1. æ”¶é›†æ‰€æœ‰è¾“å…¥çš„å›¾ç‰‡
        input_images = []
        if image1 is not None: input_images.append(image1)
        if image2 is not None: input_images.append(image2)
        if image3 is not None: input_images.append(image3)
        if image4 is not None: input_images.append(image4)

        if not input_images:
            raise ValueError("âŒ é”™è¯¯ï¼šè‡³å°‘éœ€è¦è¿æ¥ 1 å¼ å‚è€ƒå›¾ç‰‡ (image1 ~ image4)ï¼")

        print(f"ğŸ“¸ [Multi-Image] æ£€æµ‹åˆ° {len(input_images)} å¼ å‚è€ƒå›¾è¾“å…¥")

        # --- æ ¸å¿ƒé€»è¾‘ä¿®æ”¹ï¼šAuto æ¨¡å¼è®¡ç®— ---
        target_min_pixels = 3686400 # 1920 * 1920 åŸºå‡†
        
        if size == "Auto":
            # ä½¿ç”¨ç¬¬ä¸€å¼ å›¾ä½œä¸ºå°ºå¯¸å‚è€ƒ
            ref_image = input_images[0]
            # ComfyUI image shape: [Batch, Height, Width, Channels]
            input_h = ref_image.shape[1]
            input_w = ref_image.shape[2]
            aspect_ratio = input_w / input_h
            
            print(f"ğŸ” [Autoæ¨¡å¼] å‚è€ƒå›¾1å°ºå¯¸: {input_w}x{input_h} (æ¯”ä¾‹: {aspect_ratio:.2f})")
            
            # è®¡ç®—ç›®æ ‡å®½é«˜ï¼šArea = W * H = (H * AR) * H = H^2 * AR
            # => H = sqrt(Area / AR)
            new_h = math.sqrt(target_min_pixels / aspect_ratio)
            new_w = new_h * aspect_ratio
            
            # å¯¹é½åˆ° 64 çš„å€æ•°
            width = int(round(new_w / 64) * 64)
            height = int(round(new_h / 64) * 64)
            
            # å†æ¬¡æ£€æŸ¥åƒç´ æ€»é‡ï¼Œå¦‚æœä¸å¤Ÿåˆ™è¡¥è¶³
            if width * height < target_min_pixels:
                width += 64
                height += 64
                
        else:
            # å›ºå®šå°ºå¯¸æ˜ å°„
            size_map = {
                "1:1":  (2048, 2048),
                "3:4":  (1728, 2304),
                "4:3":  (2304, 1728),
                "2:3":  (1600, 2400),
                "3:2":  (2400, 1600),
                "16:9": (2560, 1440), 
                "9:16": (1440, 2560)
            }
            width, height = size_map.get(size, (2048, 2048))

        # -------------------------------------------------------

        # 2. åƒç´ æ€»é‡æœ€ç»ˆæ£€æŸ¥
        total_pixels = width * height
        if total_pixels < target_min_pixels:
            print(f"âš ï¸ è­¦å‘Š: è®¡ç®—åçš„åˆ†è¾¨ç‡ {width}x{height}={total_pixels} ä»ç•¥å°äºå»ºè®®å€¼ {target_min_pixels}ã€‚")

        # 3. æ‰¹é‡è½¬æ¢ Base64
        image_list_base64 = []
        for img in input_images:
            b64_str = self._single_tensor_to_base64(img)
            image_list_base64.append(b64_str)

        # 4. åŸºç¡€æ ¡éªŒ
        if not api_key:
            api_key = os.environ.get("ARK_API_KEY")
        if not api_key:
            raise ValueError("âŒ é”™è¯¯ï¼šAPI Key ä¸èƒ½ä¸ºç©ºï¼")
        if not endpoint_id.startswith("ep-"):
            raise ValueError(f"âŒ å‚æ•°é”™è¯¯ï¼šEndpoint ID å¿…é¡»æ˜¯ 'ep-' å¼€å¤´ã€‚")

        # 5. æ„é€ è¯·æ±‚
        size_str = f"{width}x{height}"
        print(f"ğŸ“ æœ€ç»ˆç”Ÿæˆå°ºå¯¸: {size_str} (æ¨¡å¼: {size}, æ€»åƒç´ : {total_pixels})")
        
        url = "https://ark.cn-beijing.volces.com/api/v3/images/generations"
        headers = {
            "Content-Type": "application/json",
            "Authorization": f"Bearer {api_key}"
        }

        payload = {
            "model": endpoint_id,
            "prompt": prompt,
            "image": image_list_base64, # Base64 å­—ç¬¦ä¸²åˆ—è¡¨
            "sequential_image_generation": "disabled",
            "response_format": "b64_json",
            "size": size_str,
            "stream": False,
            "watermark": watermark
        }

        print(f"ğŸš€ å‘é€è¯·æ±‚åˆ°: {endpoint_id}...")

        # 6. å‘é€è¯·æ±‚
        try:
            session = requests.Session()
            adapter = requests.adapters.HTTPAdapter(max_retries=3)
            session.mount('https://', adapter)
            session.mount('http://', adapter)

            response = session.post(
                url, 
                headers=headers, 
                json=payload, 
                timeout=180,
                verify=False,
                proxies={"http": None, "https": None}
            )
            
            if response.status_code != 200:
                error_msg = f"âŒ API è¯·æ±‚å¤±è´¥ (çŠ¶æ€ç  {response.status_code}):\n{response.text}"
                print(error_msg)
                raise RuntimeError(error_msg)

            res_json = response.json()
            
            if "data" in res_json and len(res_json["data"]) > 0:
                b64_data = res_json["data"][0].get("b64_json")
                if not b64_data:
                     raise RuntimeError("API æœªè¿”å› Base64 æ•°æ®")
                
                img_out = Image.open(BytesIO(base64.b64decode(b64_data)))
                img_rgb = img_out.convert("RGB")
                img_np = np.array(img_rgb).astype(np.float32) / 255.0
                img_tensor = torch.from_numpy(img_np).unsqueeze(0)
                
                return (img_tensor,)
            else:
                raise RuntimeError(f"âŒ æœªæ‰¾åˆ°å›¾ç‰‡æ•°æ®ï¼Œè¿”å›å†…å®¹: {res_json}")

        except Exception as e:
            print(f"âŒ è¿è¡Œå¼‚å¸¸: {e}")
            raise e

# --- æ³¨å†ŒèŠ‚ç‚¹ ---
NODE_CLASS_MAPPINGS = {
    "JM_Seeddream_45_MultiImage_Auto": Seeddream_45_MultiInput_Auto
}

NODE_DISPLAY_NAME_MAPPINGS = {
    "JM_Seeddream_45_MultiImage_Auto": "JM:Seeddream 4.5 multi_image (Auto Size)"
}